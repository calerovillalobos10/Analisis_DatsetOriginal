{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xsQH_Crge916",
        "7LDc2N6LfJcv",
        "ehzGEJUev58x",
        "70lrGQgtSVMs"
      ],
      "authorship_tag": "ABX9TyOt8NnRH2rFKQ8NRpnojVcY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calerovillalobos10/Analisis_DatsetOriginal/blob/main/Proyecto_PF_3347.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto Final: Análisis de Datos con Dataset Original"
      ],
      "metadata": {
        "id": "7wzzR8dFS4Cc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estudiantes\n",
        "\n",
        "*   Bryan Thomas Calero Villalobos\n",
        "*   Daniela Montero Parkinson\n",
        "*   Christopher Zúñiga Cárdenas"
      ],
      "metadata": {
        "id": "DjnaATEoS0Ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explicación del DataSet"
      ],
      "metadata": {
        "id": "uE7C7LKdgC42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problemática a Resolver"
      ],
      "metadata": {
        "id": "VHiS0WhAxDyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Historia o Narrativa"
      ],
      "metadata": {
        "id": "9J1Jxuc5xEjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uso práctico"
      ],
      "metadata": {
        "id": "SJoaWjjzeOBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracción de datos"
      ],
      "metadata": {
        "id": "kbI8m5bieRYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como primer paso se instalan las librerías necesarias para poder hacer todos los procesos que se realizarán en este análisis de datos"
      ],
      "metadata": {
        "id": "sw-mwGlVkv1-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qz24f_rp-8e"
      },
      "outputs": [],
      "source": [
        "!pip3 install requests\n",
        "!pip3 install pandas\n",
        "!pip3 install urllib\n",
        "!pip3 install io\n",
        "!pip3 install matplotlib\n",
        "!pip3 install seaborn\n",
        "!pip3 install scipy\n",
        "!pip3 install sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importan las librerías para poder utilizarlas en los métodos definidos"
      ],
      "metadata": {
        "id": "iqnccjSrk3YM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from pandas import json_normalize\n",
        "from requests.adapters import HTTPAdapter\n",
        "from requests.packages.urllib3.util.retry import Retry\n",
        "from urllib.parse import urlencode\n",
        "from io import StringIO\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "oYExBktnqUN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_url = f'https://sdmx.oecd.org/public/rest/data/OECD.WISE.WDP,DSD_HSL@DF_HSL_CWB_EDU,1.0/all?dimensionAtObservation=AllDimensions&format=csvfilewithlabels'"
      ],
      "metadata": {
        "id": "nfSUCwuwqZvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este método se implementó para realizar reintentos en caso de que no responda el request que se está realizando.\n",
        "\n",
        "Su funcionalidad se basa en crear una sesión HTTP que aplica reintentos automáticos cuando se producen errores temporales o de conexión en solicitudes GET."
      ],
      "metadata": {
        "id": "brPhNUcalNc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Método para crear la estrategia de reintentos\n",
        "def create_retry_session(max_retries):\n",
        "    retry_strategy = Retry(\n",
        "        total=max_retries,  # Número máximo de reintentos\n",
        "        status_forcelist=[408, 500, 502, 503, 504],  # Errores a los que se aplicarán los reintentos\n",
        "        allowed_methods=[\"GET\"],  # Solo reintentar en solicitudes GET\n",
        "        backoff_factor=1  # Tiempo de espera entre reintentos\n",
        "    )\n",
        "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "\n",
        "    # Crear una sesión de requests con el adaptador de reintentos\n",
        "    http = requests.Session()\n",
        "    http.mount(\"https://\", adapter)\n",
        "\n",
        "    return http  # Devolver la sesión con la estrategia de reintentos"
      ],
      "metadata": {
        "id": "bEXSlhUXrlom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se invoca al método que crea la sesión con reintentas pasándole la cantidad de reintentos que se desean tener"
      ],
      "metadata": {
        "id": "e0UIn7SAllxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_retries = 2\n",
        "http = create_retry_session(max_retries) #método para crear la sesión con reintentos"
      ],
      "metadata": {
        "id": "MR3dhowFrn5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se procede a realizar un consumo para obtener los datos desde el origen"
      ],
      "metadata": {
        "id": "4_d579Zrl15V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_data(max_retries=1):\n",
        "\n",
        "  all_data = [] # Lista para almacenar los datos obtenidos\n",
        "\n",
        "  try:\n",
        "    headers = {\"accept\": \"application/json\"} # Encabezados de la solicitud, incluyendo la API Key\n",
        "\n",
        "    response = http.get(api_url, headers=headers) # Realiza la solicitud HTTP al API\n",
        "    response.raise_for_status() # Lanza un error si la respuesta no es exitosa\n",
        "\n",
        "    csv_data = StringIO(response.text)\n",
        "\n",
        "  except requests.RequestException as e:\n",
        "    print(f\"{country} No más datos\")\n",
        "\n",
        "  return all_data"
      ],
      "metadata": {
        "id": "Otq3veUXl2Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis EDA Exploratorio"
      ],
      "metadata": {
        "id": "Ajv5A_cseZr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploración Inicial del Dataset"
      ],
      "metadata": {
        "id": "UdB-dWM9m-9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Proyección de primeros registros del Dataset"
      ],
      "metadata": {
        "id": "mXJEaFPrn4ww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crea un DataFrame con los datos recuperados del método fetch, con el fin de imprimir las primeras instancias e identificar cómo está formado y cuáles serán los posibles datos que tendrá cada columna"
      ],
      "metadata": {
        "id": "UEjc_HYLvTTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_original = pd.read_csv(csv_data)\n",
        "df_original.head(10)"
      ],
      "metadata": {
        "id": "hkHR93sknEqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Estructura y resumen de los datos"
      ],
      "metadata": {
        "id": "tgArZjDOop48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utiliza el método \".info\" para obtener un resumen rápido de la estructura del DataFrame"
      ],
      "metadata": {
        "id": "o8TEj2c0vGNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_original.info()"
      ],
      "metadata": {
        "id": "UyE0EzH9o0Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método de pandas \".describe\" retorna los datos de: promedio, conteo, min, max , persentiles 25/50/75 y desviacion estandar por cada columna de tipo numérico."
      ],
      "metadata": {
        "id": "yblWM0luuiWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_original.describe()"
      ],
      "metadata": {
        "id": "ZNVu3wlmo3qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploración de valores nulos"
      ],
      "metadata": {
        "id": "ooWY5RKhpLqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utiliza el método \".isnull().sum()\" para determinar las columnas que poseen datos vacíos en el conjunto de datos y la cantidad que poseen."
      ],
      "metadata": {
        "id": "8pyEFYuxp6L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Cantidad de nulos: \\n')\n",
        "nulos = df_original.isnull().sum()"
      ],
      "metadata": {
        "id": "Yfgj5nKhpz0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Detección de datos duplicados"
      ],
      "metadata": {
        "id": "GRXEXZCrpN-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evitar conclusiones incorrectas, es necesario eliminar los duplicados del dataset.\n",
        "\n",
        "Se utiliza el método \".duplicated().sum()\" para determinar la cantidad de valores duplicados"
      ],
      "metadata": {
        "id": "E9YuKh0oqJWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Cantidad de duplicados: \\n')\n",
        "duplicados = df_original.duplicated().sum()"
      ],
      "metadata": {
        "id": "ZjVLgpbpp2Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Identificar relevancia de las variables"
      ],
      "metadata": {
        "id": "vsBxEyNfpXvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Se procede a identificar y descartar columnas que no aportan información relevante para el análisis. Las columnas con 1 o menos subniveles no son útiles, debido a que no varían y, por lo tanto, no pueden contribuir a la diferenciación o clasificación en el análisis de datos."
      ],
      "metadata": {
        "id": "kqJru1ySqpOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_cat = df_original.columns.tolist() # se capturan los nombres de las columnas del DF\n",
        "\n",
        "col_descartadas = [] # se inicializa un array para capturar las columnas que se descartarán por poca relevancia\n",
        "\n",
        "# Se identifican cuántos subniveles tiene cada columna\n",
        "for col in cols_cat:\n",
        "  print(f'Columna {col}: {df_benefits_cost_sharing[col].nunique()} subniveles o distintos.')\n",
        "\n",
        "  if(df_benefits_cost_sharing[col].nunique() <= 1):\n",
        "    col_descartadas.append(col)"
      ],
      "metadata": {
        "id": "DBnNjr0Wqxxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Identificación de Outliers"
      ],
      "metadata": {
        "id": "o-v-lF8l3WBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminar espacios al principio y al final en todas las columnas de texto para mantener un estandar y buenas prácticas de limpieza"
      ],
      "metadata": {
        "id": "1xwNFxx-31UZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trim_column_names(df):\n",
        "  df.columns = df.columns.str.strip()\n",
        "  return df"
      ],
      "metadata": {
        "id": "8RVWFbW431dL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se invoca a la función para eliminar los espacios al principio y al final de los nombres de las columnas"
      ],
      "metadata": {
        "id": "p8haqN4T4jA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_original = trim_column_names(df_original)"
      ],
      "metadata": {
        "id": "54X-9YKr4h7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica un histograma para revisar outliers. El método genera un histograma para cada columna numérica en el DataFrame"
      ],
      "metadata": {
        "id": "SU0F-w6P3bCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_histograms(df):\n",
        "  # Filtrar solo las columnas numéricas\n",
        "  numeric_columns = df.select_dtypes(include=['number']).columns\n",
        "\n",
        "  # Crear un histograma para cada columna numérica\n",
        "  for col in numeric_columns:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(data=df, x=col, bins=30, kde=True)\n",
        "    plt.title(f'Histograma del parámetro: {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frecuencia')\n",
        "\n",
        "    # Mostrar el gráfico\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "DE3eSJWm3bJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se procede a generar un gráfico de caja (boxplot) para cada columna numérica especificada en el DataFrame. Para revisar outliers en variables numericas"
      ],
      "metadata": {
        "id": "w1TGYJSo956I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_boxplots(df, cols_num):\n",
        "  # Definir la estructura del gráfico\n",
        "  fig, ax = plt.subplots(nrows=len(cols_num), ncols=1, figsize=(8, 10))\n",
        "  fig.subplots_adjust(hspace=0.5)  # Espacio entre gráficos\n",
        "\n",
        "  # Crear un boxplot para cada columna especificada\n",
        "  for i, col in enumerate(cols_num):\n",
        "    sns.boxplot(x=col, data=df, ax=ax[i])  # Crear el gráfico de caja\n",
        "    ax[i].set_title(f'Gráfico del parámetro: {col}')  # Establecer el título del gráfico\n",
        "\n",
        "  # Mostrar los gráficos\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "BtvYBU72-WRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este método funciona para imprimir el valor mínimo y máximo de cada columna numérica en el DataFrame"
      ],
      "metadata": {
        "id": "rcu94lzQ_SBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_min_max_values(df, cols_num):\n",
        "  # Filtrar solo las columnas numéricas\n",
        "  cols_num = df.select_dtypes(include=['number']).columns\n",
        "\n",
        "  # Iterar sobre cada columna numérica y calcular min y max\n",
        "  for col in cols_num:\n",
        "    min_value = df[col].min()\n",
        "    max_value = df[col].max()\n",
        "    print(f'Columna: {col}')\n",
        "    print(f'Datos menor: {min_value}')\n",
        "    print(f'Datos mayor: {max_value}\\n')"
      ],
      "metadata": {
        "id": "O32hbOWK_SIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método para graficar los subniveles de cada variable categórica para identificar outliers. Se utiliza para identificar outliers en las columnas de tipo categoría. Esto con el fin de detectar, por ejemplo: mayúsculas, minúscualas, tildes dentro de las mismas categorías. Además, se grafican los parámetros de categorías con el fin de identicar si hay algún dato que necesita ser unificado, por nombre con mayúsculas o minúsculas"
      ],
      "metadata": {
        "id": "9xZycIl3FQxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_categories(df, cols_cat)\n",
        "  # Crear figura y ejes\n",
        "  fig, ax = plt.subplots(nrows=len(cols_cat), ncols=1, figsize=(10, 10 * len(cols_cat)))\n",
        "  fig.subplots_adjust(hspace=0.25)  # Ajustar espacio entre subplots\n",
        "\n",
        "  # Iterar por cada columna categórica\n",
        "  for i, col in enumerate(cols_cat):\n",
        "    sns.countplot(y=col, data=df, ax=ax[i], hue=col, palette='Set2')\n",
        "    ax[i].set_title(f'Gráfico del parámetro: {col}')\n",
        "\n",
        "    ax[i].tick_params(axis='y', rotation=0) # Usar plt.xticks() para rotar etiquetas sin problemas de locators\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vC1akD2vFRBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crean variables con las columnas numéricas del dataframe, y las categóricas"
      ],
      "metadata": {
        "id": "msdh8f71EDN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_num = df.select_dtypes(include=['number']).columns\n",
        "cols_cat = []"
      ],
      "metadata": {
        "id": "vNsqcxiWD0Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llamada de funciones"
      ],
      "metadata": {
        "id": "upSNvExsELtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_histograms(df_original) # Llamada a la función que crea los histogramas\n",
        "plot_boxplots(df_original, cols_num) # Llamada a la función que crea los gráficos de caja\n",
        "plot_categories(df_original, cols_cat) # Llamada a la función que crea los gráficos de barras para detectar visualmente si hay categorías diferentes\n",
        "print_min_max_values(df_original, cols_num) # Llama a la función que imprime el mínimo y el máximo de cada columna numérica"
      ],
      "metadata": {
        "id": "ilZRfGFCD3CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Análisis Multivariable"
      ],
      "metadata": {
        "id": "AnAvimlQIerZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza un análisis Multiversal para comprender la relación entre las variables. Primero se extraen las columnas númericas para posteriormente generar la matriz de correlacion que muestre la relación entre las columnas obtenidas, para esto se utiliza el método \".corr()\"."
      ],
      "metadata": {
        "id": "efb0k0nEIhiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_numerico = df_original.select_dtypes(include=['number','int64', 'float64']) # Obtención de las columnas númericas\n",
        "\n",
        "correlacion = df_numerico.corr() # Calcular la matriz de correlación\n",
        "correlacion"
      ],
      "metadata": {
        "id": "r7EZewd2Ihqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez se posea la matriz de correlación, procedemos a generar un mapa de calor para analizar los datos de una manera visual con el comando \".heatmap()\" de la librería seaborn.\n",
        "Para el análisis del mapa se toma lo siguiente:\n",
        "* Colores cálidos(rojos): correlaciones positivas. Indica que las columnas relacionadas van a aumentar o disminuir si la relación padre lo hace. Tambien, se puede intuir que si tienen una relación fuerte, se puede predecir o estimar el valor de la otra relacion.\n",
        "* Colores fríos(azules): correlaciones negativas. Indica que las columnas relacionadas van a hacer lo contrario en caso de que disminuya o aumente la columna padre. Tambien, si es una relación debil, conocer una de las relaciones no ayuda a predecir el valor de la otra.\n",
        "* Colores de la gama del blanco: poca o ninguna correlación."
      ],
      "metadata": {
        "id": "-qK5_SF9Im7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapa de calor de la matriz de correlación\n",
        "sns.heatmap(correlacion, annot=True, cmap='coolwarm')\n",
        "plt.title('Mapa de calor')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DEIMrf2CIppx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Análisis Univariable"
      ],
      "metadata": {
        "id": "BrNwiZCQIvh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza un análisis univariable para resumir las tendencias y presencias en los valores atípicos."
      ],
      "metadata": {
        "id": "xYcP9hQOI23_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "df_numerico.plot(kind='box', subplots=True, layout=(int(len(df_numerico.columns)/2), 2), figsize=(8, 8), title='Resumen de distribución')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f2w6QbXrIvDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descripción del conjunto de datos"
      ],
      "metadata": {
        "id": "TBQx_B6geekz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El conjunto de datos consta de..."
      ],
      "metadata": {
        "id": "x7hGiNjVq8my"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis de los parámetros"
      ],
      "metadata": {
        "id": "AsGWvbD6ep6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preguntas clave:"
      ],
      "metadata": {
        "id": "DpAPKfB0e0An"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detección de valores atípicos en las mediciones"
      ],
      "metadata": {
        "id": "-Tnesm2DejIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procesamiento de Datos (Limpieza de datos y Transformación)"
      ],
      "metadata": {
        "id": "yEtjIJxOe4WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eliminación de duplicados"
      ],
      "metadata": {
        "id": "eCInN5V4ghco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente método se utiliza para detectar cuántos duplicados hay en los datos y eliminarlos si se encuentran"
      ],
      "metadata": {
        "id": "f2erNHGgyger"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_duplicates(df, duplicados):\n",
        "  if duplicados > 1:\n",
        "    print(f'Tamaño previo: {df.shape}')\n",
        "\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    print(f'Tamaño posterior: {df.shape}')\n",
        "  else:\n",
        "    print('No hay filas duplicadas')\n",
        "\n",
        "# Llamada a la función para realizar el proceso\n",
        "drop_duplicates(df_original, duplicados)"
      ],
      "metadata": {
        "id": "ldnY0datyTfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformación de datos"
      ],
      "metadata": {
        "id": "hj1k3Vrugq50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elimina los espacios en blanco al principio y al final de cada valor en un DataFrame siempre y cuando sea de tipo string o de tipo object"
      ],
      "metadata": {
        "id": "PbF0J-Tj4yv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trim_whitespace(df):\n",
        "  df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" || x.dtype == \"str\" else x)\n",
        "  return df"
      ],
      "metadata": {
        "id": "IJVCCDtD4tT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminar los espacios en blanco"
      ],
      "metadata": {
        "id": "omoTjpwd5Yv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_original = trim_whitespace(df_original)"
      ],
      "metadata": {
        "id": "G29mDTwA5UP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se procede a reemplazar los registros que posean '?' ya que es recomendable eliminar estas instancias. Debido a que no aportan nada al entrenamiento de los modelos y también porque así se realiza una estandarización en los datos"
      ],
      "metadata": {
        "id": "YcWMzCw10mLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_original.replace('?', np.nan, inplace=True)"
      ],
      "metadata": {
        "id": "CSS4tHyN0i_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codificar las variables categóricas significa transformar las categorías en valores numéricos para que los algoritmos de Machine Learning puedan procesarlas. Esto se hará para ampliar la compatibilidad entre los algoritmos a utilizar."
      ],
      "metadata": {
        "id": "vlpPxp7GJJ5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente método aplica LabelEncoder a las columnas especificadas de un DataFrame"
      ],
      "metadata": {
        "id": "uJYk2ilNJPg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_labels(df, columns):\n",
        "  label_encoder = LabelEncoder()  # Creamos el codificador\n",
        "\n",
        "  for column in columns:\n",
        "    if column in df.columns:\n",
        "      df[column] = label_encoder.fit_transform(df[column])\n",
        "    else:\n",
        "      print(f'La columna \"{column}\" no se encuentra en el DataFrame.')\n",
        "\n",
        "  return df\n",
        "\n",
        "# Columnas a las que se le aplciará el label_encoder\n",
        "columns_to_encode = ['', '', '']\n",
        "df_data = encode_labels(df_data, columns_to_encode)"
      ],
      "metadata": {
        "id": "bgXqSdPnJP1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eliminación de nulos"
      ],
      "metadata": {
        "id": "X7Izr3l9gjKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se proceden a eliminar nulos, ya que según el análisis realizado, la eliminación de estos nulos no afecta a la hora del entrenamiento de modelos o el análisis de los datos que se quiere realizar"
      ],
      "metadata": {
        "id": "EyvhC17I0QvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_original.dropna()"
      ],
      "metadata": {
        "id": "QZanrCvk0OKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eliminación de outliers"
      ],
      "metadata": {
        "id": "E7cDJlBNzlyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selección de características"
      ],
      "metadata": {
        "id": "sbgyYRu6yo5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se proceden a eliminar las columnas menos relevantes (si es que las hay). Además, con \"inplace=True\": modifica datos directamente sin crear un dataframe nuevo"
      ],
      "metadata": {
        "id": "z2yXDBQ2yuBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_original.drop(columns=col_descartadas, inplace=True)"
      ],
      "metadata": {
        "id": "-vP26PlgyuIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis EDA luego de limpieza"
      ],
      "metadata": {
        "id": "xsQH_Crge916"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entender la estructura de los datos"
      ],
      "metadata": {
        "id": "OjDniDNbfAd2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detección de valores atípicos (outliers)"
      ],
      "metadata": {
        "id": "d6sudDtHfEjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detección de valores faltantes"
      ],
      "metadata": {
        "id": "F5ZmnyyIfGYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementación de los Algoritmos"
      ],
      "metadata": {
        "id": "zMqQB1CXg56l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribución de datos para entrenamiento"
      ],
      "metadata": {
        "id": "ArwpJqJMhIEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se debe separar las características (X) y la variable objetivo (y).\n",
        "\n",
        "x = variables para realizar la predicción, se conocen tambien como variables de entrada o características.\n",
        "\n",
        "y = variable predicción, se conoce como variable de salida o etiqueta"
      ],
      "metadata": {
        "id": "JbMvYbn8Lif0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_data[['', '', '']]\n",
        "y = df_data['']"
      ],
      "metadata": {
        "id": "f1ZjZpIvLmtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se procede a dividir el dataset en conjuntos de entrenamiento y prueba. El random_state se utiliza para establecer una semilla para el generador de números aleatorios. Esto garantiza que la división del conjunto de datos en conjuntos de entrenamiento y prueba sea reproducible. Utilizar el mismo random_state en diferentes ejecuciones permite evaluar cómo cambios en otros aspectos del modelo"
      ],
      "metadata": {
        "id": "kvpEjWG3KhyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "yFfc6Z28KrUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrices de Confusión"
      ],
      "metadata": {
        "id": "FsNcdAY2hzaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo"
      ],
      "metadata": {
        "id": "6ezw9S6OhMnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo"
      ],
      "metadata": {
        "id": "SHJpNbNEhP4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo"
      ],
      "metadata": {
        "id": "TRYwnx-whQOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo"
      ],
      "metadata": {
        "id": "6m_b2gePhSFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis Comparativo de los Modelos"
      ],
      "metadata": {
        "id": "pwJ1kCwnhXGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementación de Keras"
      ],
      "metadata": {
        "id": "or9fKo-7hs4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación de desempeño"
      ],
      "metadata": {
        "id": "9lKs_xEFhZ2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una función para evaluar el modelo con los datos de exactitud, precisión, exhaustividad y puntuación F1(Medida de balance entre precisión y exhaustividad)"
      ],
      "metadata": {
        "id": "HjEBHUVcLxR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluar_modelo(y_test, y_pred):\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "  recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "  f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "\n",
        "  return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "Ndca-uiuLxXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se agrega en un listado los resultados de la evaluación de cada modelo para ser comparados en una tabla"
      ],
      "metadata": {
        "id": "cAnSwpCWL4xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = {} # Evaluación de cada modelo\n",
        "resultados['Random Forest'] = evaluar_modelo(y_test, predict_random_forest) # Random Forest\n",
        "resultados['Árbol de Decisión'] = evaluar_modelo(y_test, predict_decision_tree) # Árbol de Decisión\n",
        "resultados['Naive Bayes'] = evaluar_modelo(y_test, predict_naive_bayes) # Naive Bayes\n",
        "resultados['Redes Neuronales'] = evaluar_modelo(y_test, predict_neural_network) # Redes Neuronales"
      ],
      "metadata": {
        "id": "S1Jlf9r-L8gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrices de Confusión"
      ],
      "metadata": {
        "id": "eQ0euTohhgUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparativa y Visualización de datos"
      ],
      "metadata": {
        "id": "7LDc2N6LfJcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribución"
      ],
      "metadata": {
        "id": "-_9OvjYvfasj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis de tendencia"
      ],
      "metadata": {
        "id": "4VI7hgS8fdAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Síntesis de Resultados"
      ],
      "metadata": {
        "id": "ehzGEJUev58x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hallazgos Clave"
      ],
      "metadata": {
        "id": "lezGkdYpv_UH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resultados vs Hipótesis"
      ],
      "metadata": {
        "id": "GJrM-RHAwB8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acciones"
      ],
      "metadata": {
        "id": "428DXBGwwFXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusiones"
      ],
      "metadata": {
        "id": "MRgy06T4fnzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referencias"
      ],
      "metadata": {
        "id": "70lrGQgtSVMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cramér, H. (1946). Mathematical Methods of Statistics. Princeton University Press.\n",
        "\n",
        "Guzman, M. (2022, 23 de mayo). *Guía para limpiar datos con Pandas*. Medium. https://medium.com/nowports-tech/guia-limpiar-datos-con-pandas-3dc634c47e11\n",
        "\n",
        "Nik. (s.f.). How to Calculate Cramer’s V in Python. datagy.io1. Recuperado de  https://datagy.io/cramers-v-python/\n",
        "\n",
        "The pandas development team. (2024). *pandas.DataFrame — pandas 2.1.1 documentation.* https://pandas.pydata.org/docs/reference/frame.html"
      ],
      "metadata": {
        "id": "XcQ59gEVScsf"
      }
    }
  ]
}